{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgfOtsYrPNij",
        "outputId": "a594dba0-4b88-4ee2-dd54-b66cca23790f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MyApplication\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "9TfXJdpcPVuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Alice\", 34, \"HR\"), (\"Bob\", 45, \"Tech\"), (\"Charlie\", 29, \"HR\")]\n",
        "df = spark.createDataFrame(data, [\"name\", \"age\", \"department\"])\n",
        "\n",
        "# # From CSV file\n",
        "# df = spark.read.csv(\"path/to/file.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# # From Parquet\n",
        "# df = spark.read.parquet(\"path/to/file.parquet\")\n",
        "\n",
        "# # From JSON\n",
        "# df = spark.read.json(\"path/to/file.json\")"
      ],
      "metadata": {
        "id": "Qpf5KqGBPX9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()\n",
        "df.printSchema()\n",
        "\n",
        "df.filter(df[\"age\"] > 30).show()\n",
        "df.filter(\"age > 30\").show()  # Using SQL expression"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLdZdePxPhIE",
        "outputId": "16d37209-35b6-4ee8-949e-dfb40106a4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+\n",
            "|   name|age|department|\n",
            "+-------+---+----------+\n",
            "|  Alice| 34|        HR|\n",
            "|    Bob| 45|      Tech|\n",
            "|Charlie| 29|        HR|\n",
            "+-------+---+----------+\n",
            "\n",
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            "\n",
            "+-----+---+----------+\n",
            "| name|age|department|\n",
            "+-----+---+----------+\n",
            "|Alice| 34|        HR|\n",
            "|  Bob| 45|      Tech|\n",
            "+-----+---+----------+\n",
            "\n",
            "+-----+---+----------+\n",
            "| name|age|department|\n",
            "+-----+---+----------+\n",
            "|Alice| 34|        HR|\n",
            "|  Bob| 45|      Tech|\n",
            "+-----+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count rows\n",
        "df.count()\n",
        "\n",
        "df.select(\"age\").distinct().show()\n",
        "df.sort(df[\"age\"].desc()).show()\n",
        "\n",
        "# Limit\n",
        "df.limit(5).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asW9QbcZPrTa",
        "outputId": "171ba3cb-9881-4baf-90eb-36aa11106f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|age|\n",
            "+---+\n",
            "| 34|\n",
            "| 29|\n",
            "| 45|\n",
            "+---+\n",
            "\n",
            "+-------+---+----------+\n",
            "|   name|age|department|\n",
            "+-------+---+----------+\n",
            "|    Bob| 45|      Tech|\n",
            "|  Alice| 34|        HR|\n",
            "|Charlie| 29|        HR|\n",
            "+-------+---+----------+\n",
            "\n",
            "+-------+---+----------+\n",
            "|   name|age|department|\n",
            "+-------+---+----------+\n",
            "|  Alice| 34|        HR|\n",
            "|    Bob| 45|      Tech|\n",
            "|Charlie| 29|        HR|\n",
            "+-------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregation and Grouping"
      ],
      "metadata": {
        "id": "lQiqOsTfQCsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "df.select(F.max(\"age\"), F.min(\"age\"), F.avg(\"age\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voWUv_PdQFKz",
        "outputId": "bc3da04d-9b4a-42b3-8138-19ff9c60f828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+--------+\n",
            "|max(age)|min(age)|avg(age)|\n",
            "+--------+--------+--------+\n",
            "|      45|      29|    36.0|\n",
            "+--------+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregation functions"
      ],
      "metadata": {
        "id": "LB_Uq1XMRAYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Aggregations\n",
        "df.select(F.max(\"age\"), F.min(\"age\"), F.avg(\"age\")).show()\n",
        "\n",
        "# GroupBy\n",
        "df.groupBy(\"department\").count().show()\n",
        "df.groupBy(\"department\").agg(F.avg(\"salary\").alias(\"avg_salary\")).show()\n",
        "\n",
        "# Window functions\n",
        "from pyspark.sql.window import Window\n",
        "window_spec = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
        "df.withColumn(\"rank\", F.rank().over(window_spec)).show()"
      ],
      "metadata": {
        "id": "4GMkYprGRAAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Joining Dataframes"
      ],
      "metadata": {
        "id": "vx0VzjvbQ9jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inner join\n",
        "employees.join(departments, \"department_id\").show()\n",
        "\n",
        "# Left outer join\n",
        "employees.join(departments, \"department_id\", \"left\").show()\n",
        "\n",
        "# Using different column names\n",
        "employees.join(departments,\n",
        "              employees[\"dept_id\"] == departments[\"id\"]).show()\n",
        "\n",
        "# Multiple join conditions\n",
        "df1.join(df2,\n",
        "        (df1[\"id\"] == df2[\"id\"]) & (df1[\"type\"] == df2[\"type\"])).show()"
      ],
      "metadata": {
        "id": "Pt2jsjvLQ5oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register DataFrame as a temporary view\n",
        "df.createOrReplaceTempView(\"people\")\n",
        "\n",
        "# Run SQL queries\n",
        "result = spark.sql(\"SELECT * FROM people WHERE age > 30\")\n",
        "result.show()\n",
        "\n",
        "# Register as a global temporary view\n",
        "df.createGlobalTempView(\"people\")\n",
        "\n",
        "# Access global temporary view\n",
        "spark.sql(\"SELECT * FROM global_temp.people\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KchQxKLrQzJ8",
        "outputId": "61d66c10-3577-4b5f-f716-c1144e420561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+\n",
            "| name|age|department|\n",
            "+-----+---+----------+\n",
            "|Alice| 34|        HR|\n",
            "|  Bob| 45|      Tech|\n",
            "+-----+---+----------+\n",
            "\n",
            "+-------+---+----------+\n",
            "|   name|age|department|\n",
            "+-------+---+----------+\n",
            "|  Alice| 34|        HR|\n",
            "|    Bob| 45|      Tech|\n",
            "|Charlie| 29|        HR|\n",
            "+-------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X25ySW8vRLPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Sources and Sinks"
      ],
      "metadata": {
        "id": "ROiH6QhqRNrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV\n",
        "df = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .load(\"path/to/file.csv\")\n",
        "\n",
        "# JSON\n",
        "df = spark.read.json(\"path/to/file.json\")\n",
        "\n",
        "# Parquet\n",
        "df = spark.read.parquet(\"path/to/directory\")\n",
        "\n",
        "# ORC\n",
        "df = spark.read.orc(\"path/to/file.orc\")\n",
        "\n",
        "# JDBC\n",
        "df = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"url\", \"jdbc:postgresql:dbserver\") \\\n",
        "    .option(\"dbtable\", \"schema.table\") \\\n",
        "    .option(\"user\", \"username\") \\\n",
        "    .option(\"password\", \"password\") \\\n",
        "    .load()"
      ],
      "metadata": {
        "id": "8it4eucGRHbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parquet (default)\n",
        "df.write.save(\"path/to/output\")\n",
        "\n",
        "# Specific format\n",
        "df.write.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .save(\"path/to/output\")\n",
        "\n",
        "# Available modes: append, overwrite, ignore, error\n",
        "\n",
        "# Partitioning\n",
        "df.write.partitionBy(\"year\", \"month\") \\\n",
        "    .format(\"parquet\") \\\n",
        "    .save(\"path/to/output\")"
      ],
      "metadata": {
        "id": "3a4uvfHDRRTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structed Streaming"
      ],
      "metadata": {
        "id": "QnxU-CrHRaGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create streaming DataFrame from socket source\n",
        "streaming_df = spark \\\n",
        "    .readStream \\\n",
        "    .format(\"socket\") \\\n",
        "    .option(\"host\", \"localhost\") \\\n",
        "    .option(\"port\", 9999) \\\n",
        "    .load()\n",
        "\n",
        "# Process data\n",
        "word_counts = streaming_df \\\n",
        "    .selectExpr(\"explode(split(value, ' ')) as word\") \\\n",
        "    .groupBy(\"word\") \\\n",
        "    .count()\n",
        "\n",
        "# Start the query\n",
        "query = word_counts \\\n",
        "    .writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"console\") \\\n",
        "    .start()\n",
        "\n",
        "# Wait for the query to terminate\n",
        "query.awaitTermination()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "B7CYt3pxRZX5",
        "outputId": "4c91c3cb-e507-455d-a3ef-da5066252cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StreamingQueryException",
          "evalue": "[STREAM_FAILED] Query [id = 295882ce-5408-4e08-94a7-7104e54b294e, runId = 5d8ef8e9-3304-4e36-bef7-d063485c8dc4] terminated with exception: Connection refused (Connection refused)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStreamingQueryException\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d4aa62b035dc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Wait for the query to terminate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/streaming/query.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStreamingQueryException\u001b[0m: [STREAM_FAILED] Query [id = 295882ce-5408-4e08-94a7-7104e54b294e, runId = 5d8ef8e9-3304-4e36-bef7-d063485c8dc4] terminated with exception: Connection refused (Connection refused)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Emp Data & Schema\n",
        "\n",
        "emp_data_1 = [\n",
        "    [\"001\",\"101\",\"John Doe\",\"30\",\"Male\",\"50000\",\"2015-01-01\"],\n",
        "    [\"002\",\"101\",\"Jane Smith\",\"25\",\"Female\",\"45000\",\"2016-02-15\"],\n",
        "    [\"003\",\"102\",\"Bob Brown\",\"35\",\"Male\",\"55000\",\"2014-05-01\"],\n",
        "    [\"004\",\"102\",\"Alice Lee\",\"28\",\"Female\",\"48000\",\"2017-09-30\"],\n",
        "    [\"005\",\"103\",\"Jack Chan\",\"40\",\"Male\",\"60000\",\"2013-04-01\"],\n",
        "    [\"006\",\"103\",\"Jill Wong\",\"32\",\"Female\",\"52000\",\"2018-07-01\"],\n",
        "    [\"007\",\"101\",\"James Johnson\",\"42\",\"Male\",\"70000\",\"2012-03-15\"],\n",
        "    [\"008\",\"102\",\"Kate Kim\",\"29\",\"Female\",\"51000\",\"2019-10-01\"],\n",
        "    [\"009\",\"103\",\"Tom Tan\",\"33\",\"Male\",\"58000\",\"2016-06-01\"],\n",
        "    [\"010\",\"104\",\"Lisa Lee\",\"27\",\"Female\",\"47000\",\"2018-08-01\"]\n",
        "]\n",
        "\n",
        "emp_data_2 = [\n",
        "    [\"011\",\"104\",\"David Park\",\"38\",\"Male\",\"65000\",\"2015-11-01\"],\n",
        "    [\"012\",\"105\",\"Susan Chen\",\"31\",\"Female\",\"54000\",\"2017-02-15\"],\n",
        "    [\"013\",\"106\",\"Brian Kim\",\"45\",\"Male\",\"75000\",\"2011-07-01\"],\n",
        "    [\"014\",\"107\",\"Emily Lee\",\"26\",\"Female\",\"46000\",\"2019-01-01\"],\n",
        "    [\"015\",\"106\",\"Michael Lee\",\"37\",\"Male\",\"63000\",\"2014-09-30\"],\n",
        "    [\"016\",\"107\",\"Kelly Zhang\",\"30\",\"Female\",\"49000\",\"2018-04-01\"],\n",
        "    [\"017\",\"105\",\"George Wang\",\"34\",\"Male\",\"57000\",\"2016-03-15\"],\n",
        "    [\"018\",\"104\",\"Nancy Liu\",\"29\",\"\",\"50000\",\"2017-06-01\"],\n",
        "    [\"019\",\"103\",\"Steven Chen\",\"36\",\"Male\",\"62000\",\"2015-08-01\"],\n",
        "    [\"020\",\"102\",\"Grace Kim\",\"32\",\"Female\",\"53000\",\"2018-11-01\"]\n",
        "]\n",
        "\n",
        "emp_schema = \"employee_id string, department_id string, name string, age string, gender string, salary string, hire_date string\""
      ],
      "metadata": {
        "id": "xgdqhglGSxUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emp_df_1 = spark.createDataFrame(data=emp_data_1, schema=emp_schema)\n",
        "emp_df_2 = spark.createDataFrame(data=emp_data_2, schema=emp_schema)\n"
      ],
      "metadata": {
        "id": "YvkXn4uoS8dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show emp dataframe (ACTION)\n",
        "\n",
        "emp_df_1.show()\n",
        "emp_df_2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jytDphICTGx_",
        "outputId": "5b722705-9a44-4ab1-ee6a-2e8a02c9e0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-------------+---+------+------+----------+\n",
            "|employee_id|department_id|         name|age|gender|salary| hire_date|\n",
            "+-----------+-------------+-------------+---+------+------+----------+\n",
            "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n",
            "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n",
            "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n",
            "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n",
            "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n",
            "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n",
            "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n",
            "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n",
            "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|\n",
            "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n",
            "+-----------+-------------+-------------+---+------+------+----------+\n",
            "\n",
            "+-----------+-------------+-----------+---+------+------+----------+\n",
            "|employee_id|department_id|       name|age|gender|salary| hire_date|\n",
            "+-----------+-------------+-----------+---+------+------+----------+\n",
            "|        011|          104| David Park| 38|  Male| 65000|2015-11-01|\n",
            "|        012|          105| Susan Chen| 31|Female| 54000|2017-02-15|\n",
            "|        013|          106|  Brian Kim| 45|  Male| 75000|2011-07-01|\n",
            "|        014|          107|  Emily Lee| 26|Female| 46000|2019-01-01|\n",
            "|        015|          106|Michael Lee| 37|  Male| 63000|2014-09-30|\n",
            "|        016|          107|Kelly Zhang| 30|Female| 49000|2018-04-01|\n",
            "|        017|          105|George Wang| 34|  Male| 57000|2016-03-15|\n",
            "|        018|          104|  Nancy Liu| 29|      | 50000|2017-06-01|\n",
            "|        019|          103|Steven Chen| 36|  Male| 62000|2015-08-01|\n",
            "|        020|          102|  Grace Kim| 32|Female| 53000|2018-11-01|\n",
            "+-----------+-------------+-----------+---+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_df_1.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29x-8D8DTKAT",
        "outputId": "36c6c93a-5157-4758-f78e-996473ffcb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_id: string (nullable = true)\n",
            " |-- department_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            " |-- hire_date: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNION and UNION ALL\n",
        "# select * from emp_data_1 UNION select * from emp_df_2\n",
        "emp = emp_df_1.unionAll(emp_df_2)"
      ],
      "metadata": {
        "id": "VvHCy6S3TOP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emp.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGL-jMOBTWPW",
        "outputId": "8cbc46ed-5465-4859-debd-c14eefe408c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-------------+---+------+------+----------+\n",
            "|employee_id|department_id|         name|age|gender|salary| hire_date|\n",
            "+-----------+-------------+-------------+---+------+------+----------+\n",
            "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n",
            "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n",
            "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n",
            "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n",
            "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n",
            "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n",
            "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n",
            "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n",
            "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|\n",
            "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n",
            "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|\n",
            "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|\n",
            "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|\n",
            "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|\n",
            "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|\n",
            "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|\n",
            "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|\n",
            "|        018|          104|    Nancy Liu| 29|      | 50000|2017-06-01|\n",
            "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|\n",
            "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|\n",
            "+-----------+-------------+-------------+---+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc, asc, col\n",
        "emp_sorted = emp.orderBy(col(\"salary\").asc())"
      ],
      "metadata": {
        "id": "5MyToTI9TgNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emp_sorted.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCHnHk61Tt9y",
        "outputId": "324d49a2-0b77-4f59-c840-e40d6763d204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-------------+---+------+------+----------+\n",
            "|employee_id|department_id|         name|age|gender|salary| hire_date|\n",
            "+-----------+-------------+-------------+---+------+------+----------+\n",
            "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n",
            "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|\n",
            "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n",
            "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n",
            "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|\n",
            "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n",
            "|        018|          104|    Nancy Liu| 29|      | 50000|2017-06-01|\n",
            "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n",
            "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n",
            "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|\n",
            "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|\n",
            "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n",
            "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|\n",
            "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|\n",
            "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n",
            "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|\n",
            "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|\n",
            "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|\n",
            "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n",
            "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|\n",
            "+-----------+-------------+-------------+---+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregation\n",
        "# select dept_id, count(employee_id) as total_dept_count from emp_sorted group by dept_id\n",
        "from pyspark.sql.functions import count\n",
        "\n",
        "emp = emp_sorted.groupBy(\"department_id\").agg(count(\"employee_id\")).alias(\"total_dept_count\")"
      ],
      "metadata": {
        "id": "Otp8t1lhTyvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emp.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGh_OnGvUZIZ",
        "outputId": "d5939555-25d3-4e23-8e38-7f2bbf241f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------------------+\n",
            "|department_id|count(employee_id)|\n",
            "+-------------+------------------+\n",
            "|          101|                 3|\n",
            "|          102|                 4|\n",
            "|          103|                 4|\n",
            "|          104|                 3|\n",
            "|          107|                 2|\n",
            "|          106|                 2|\n",
            "|          105|                 2|\n",
            "+-------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregation\n",
        "# select dept_id, sum(salary) as total_dept_salary from emp_sorted group by dept_id\n",
        "from pyspark.sql.functions import sum\n",
        "\n",
        "emp_sum = emp_sorted.groupBy(\"department_id\").agg(sum(\"salary\").alias(\"total_dept_salary\"))"
      ],
      "metadata": {
        "id": "-AQHiWD0UkUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emp_sum.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07UNfG9UUmaN",
        "outputId": "24cbd536-b537-4244-c78f-a0e91be91718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----------------+\n",
            "|department_id|total_dept_salary|\n",
            "+-------------+-----------------+\n",
            "|          101|         165000.0|\n",
            "|          107|          95000.0|\n",
            "|          104|         162000.0|\n",
            "|          102|         207000.0|\n",
            "|          103|         232000.0|\n",
            "|          106|         138000.0|\n",
            "|          105|         111000.0|\n",
            "+-------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregation with having clause\n",
        "# select dept_id, avg(salary) as avg_dept_salary from emp_sorted  group by dept_id having avg(salary) > 50000\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "emp_avg = emp_sorted.groupBy(\"department_id\").agg(avg(\"salary\").alias(\"avg_dept_salary\")).where(\"avg_dept_salary > 50000\")"
      ],
      "metadata": {
        "id": "rsSX9osaUuN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emp_avg.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYO1Ji1JVQGJ",
        "outputId": "5fceeee2-e7e0-43c5-9e69-b505b7dd0638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+\n",
            "|department_id|avg_dept_salary|\n",
            "+-------------+---------------+\n",
            "|          101|        55000.0|\n",
            "|          104|        54000.0|\n",
            "|          102|        51750.0|\n",
            "|          103|        58000.0|\n",
            "|          106|        69000.0|\n",
            "|          105|        55500.0|\n",
            "+-------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bonus TIP - unionByName\n",
        "# In case the column sequence is different\n",
        "emp_df_2_other = emp_df_2.select(\"employee_id\", \"salary\", \"department_id\", \"name\", \"hire_date\", \"gender\", \"age\")\n",
        "\n",
        "emp_df_1.printSchema()\n",
        "emp_df_2_other.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHoRUkkCVXAa",
        "outputId": "971e3585-315d-40bd-92ae-7c1d05ee7e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_id: string (nullable = true)\n",
            " |-- department_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            " |-- hire_date: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- employee_id: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            " |-- department_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- hire_date: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_fixed = emp_df_1.unionByName(emp_df_2_other)"
      ],
      "metadata": {
        "id": "zSdSsxzNWE3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emp_fixed.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWZbSgsjWZeV",
        "outputId": "def776d8-1ab3-4517-e9f0-e9b3ee2a64db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-------------+---+------+------+----------+\n",
            "|employee_id|department_id|         name|age|gender|salary| hire_date|\n",
            "+-----------+-------------+-------------+---+------+------+----------+\n",
            "|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n",
            "|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n",
            "|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n",
            "|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n",
            "|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n",
            "|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n",
            "|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n",
            "|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n",
            "|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|\n",
            "|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n",
            "|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|\n",
            "|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|\n",
            "|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|\n",
            "|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|\n",
            "|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|\n",
            "|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|\n",
            "|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|\n",
            "|        018|          104|    Nancy Liu| 29|      | 50000|2017-06-01|\n",
            "|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|\n",
            "|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|\n",
            "+-----------+-------------+-------------+---+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_fixed.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi6FKsd0Wbro",
        "outputId": "3661cc33-848b-4e86-b630-7683d11aa67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}