{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4sLJrP9-b9e0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "n1eXEnRIQApa",
        "outputId": "cf5095cb-6c07-4c95-a8fb-10e548151d2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7eab53be6f90>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://857769e30c58:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Writing to Multiple Sinks</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Create the Spark Session\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession\n",
        "    .builder\n",
        "    .appName(\"PySpark Utils\")\n",
        "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True)\n",
        "    # .master(\"local[*]\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField\n",
        "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
        "\n",
        "# Create data\n",
        "data = [\n",
        "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
        "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
        "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
        "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
        "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
        "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
        " ]\n",
        "\n",
        "# Create schema\n",
        "schema = StructType([\n",
        "     StructField('name', StructType([\n",
        "        StructField('firstname', StringType(), True),\n",
        "        StructField('middlename', StringType(), True),\n",
        "         StructField('lastname', StringType(), True)\n",
        "     ])),\n",
        "     StructField('languages', ArrayType(StringType()), True),\n",
        "     StructField('state', StringType(), True),\n",
        "     StructField('gender', StringType(), True)\n",
        " ])\n",
        "\n",
        "df = spark.createDataFrame(data=data, schema=schema)\n",
        "df.printSchema()\n",
        "df.show()\n",
        "\n",
        "# Using equal condition\n",
        "df.filter(df.state == \"OH\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1rIKM_IZSK-",
        "outputId": "35f85df8-4ae5-4f53-af9d-7b7a713dd6f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- languages: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            "\n",
            "+--------------------+------------------+-----+------+\n",
            "|                name|         languages|state|gender|\n",
            "+--------------------+------------------+-----+------+\n",
            "|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n",
            "|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n",
            "| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n",
            "|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n",
            "|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n",
            "|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
            "+--------------------+------------------+-----+------+\n",
            "\n",
            "+----------------------+------------------+-----+------+\n",
            "|name                  |languages         |state|gender|\n",
            "+----------------------+------------------+-----+------+\n",
            "|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n",
            "|{Julia, , Williams}   |[CSharp, VB]      |OH   |F     |\n",
            "|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n",
            "+----------------------+------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Filter multiple conditions\n",
        "df.filter( (df.state  == \"OH\") & (df.gender  == \"M\") ) \\\n",
        "    .show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PL5AynvaCAx",
        "outputId": "842db06c-bc71-4846-eb14-7517cdf64297"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+------------------+-----+------+\n",
            "|name                  |languages         |state|gender|\n",
            "+----------------------+------------------+-----+------+\n",
            "|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n",
            "|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n",
            "+----------------------+------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter IS IN List values\n",
        "li=[\"OH\",\"CA\",\"DE\"]\n",
        "\n",
        "df.filter(df.state.isin(li)) \\\n",
        "    .show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0ynJMpeaMfn",
        "outputId": "e15aa80a-f1b6-46ee-8447-460f202c213b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+------------------+-----+------+\n",
            "|name                  |languages         |state|gender|\n",
            "+----------------------+------------------+-----+------+\n",
            "|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n",
            "|{Julia, , Williams}   |[CSharp, VB]      |OH   |F     |\n",
            "|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n",
            "+----------------------+------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df.name.lastname == 'Williams').show(truncate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47AvczqLadXk",
        "outputId": "7f1972ae-ebd6-4d1c-f232-6bd054051833"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------+-----+------+\n",
            "|                name|   languages|state|gender|\n",
            "+--------------------+------------+-----+------+\n",
            "| {Julia, , Williams}|[CSharp, VB]|   OH|     F|\n",
            "|{Mike, Mary, Will...|[Python, VB]|   OH|     M|\n",
            "+--------------------+------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0LNBtelAa8k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How is distinct() different from dropDuplicate()?\n",
        "distinct() and dropDuplicates() in PySpark are used to remove duplicate rows, but there is a subtle difference. distinct() considers all columns when identifying duplicates, while dropDuplicates() allowing you to specify a subset of columns to determine uniqueness."
      ],
      "metadata": {
        "id": "inf4HWibb-1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Data\n",
        "data = [(\"James\", \"Sales\", 3000), \\\n",
        "    (\"Michael\", \"Sales\", 4600), \\\n",
        "    (\"Robert\", \"Sales\", 4100), \\\n",
        "    (\"Maria\", \"Finance\", 3000), \\\n",
        "    (\"James\", \"Sales\", 3000), \\\n",
        "    (\"Scott\", \"Finance\", 3300), \\\n",
        "    (\"Jen\", \"Finance\", 3900), \\\n",
        "    (\"Jeff\", \"Marketing\", 3000), \\\n",
        "    (\"Kumar\", \"Marketing\", 2000), \\\n",
        "    (\"Saif\", \"Sales\", 4100) \\\n",
        "  ]\n",
        "\n",
        "# Create DataFrame\n",
        "columns= [\"employee_name\", \"department\", \"salary\"]\n",
        "df = spark.createDataFrame(data = data, schema = columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuNlk09Za9Qb",
        "outputId": "8b50c5d1-4bfd-4ba5-afca-57b4dd9c9086"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|James        |Sales     |3000  |\n",
            "|Michael      |Sales     |4600  |\n",
            "|Robert       |Sales     |4100  |\n",
            "|Maria        |Finance   |3000  |\n",
            "|James        |Sales     |3000  |\n",
            "|Scott        |Finance   |3300  |\n",
            "|Jen          |Finance   |3900  |\n",
            "|Jeff         |Marketing |3000  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Saif         |Sales     |4100  |\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropDisDF = df.dropDuplicates([\"department\",\"salary\"])\n",
        "print(\"Distinct count of department & salary : \"+str(dropDisDF.count()))\n",
        "dropDisDF.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKegkCEia_dA",
        "outputId": "492f1f0c-c817-418e-f444-2b5c60fd06eb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distinct count of department & salary : 8\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|Maria        |Finance   |3000  |\n",
            "|Scott        |Finance   |3300  |\n",
            "|Jen          |Finance   |3900  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Jeff         |Marketing |3000  |\n",
            "|James        |Sales     |3000  |\n",
            "|Robert       |Sales     |4100  |\n",
            "|Michael      |Sales     |4600  |\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NELZMBXVc_YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum\n",
        "\n",
        "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
        "  (\"Michael\",\"Sales\",\"NV\",86000,56,20000),\n",
        "  (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
        "  (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n",
        "  (\"Raman\",\"Finance\",\"DE\",99000,40,24000),\n",
        "  (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n",
        "  (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n",
        "  (\"Jeff\",\"Marketing\",\"NV\",80000,25,18000),\n",
        "  (\"Kumar\",\"Marketing\",\"NJ\",91000,50,21000)\n",
        "]\n",
        "schema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
        "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)\n",
        "new_df = df.groupBy(\"state\") \\\n",
        "  .agg(sum(\"salary\").alias(\"sum_salary\"))\n",
        "\n",
        "new_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKwBS4CRc_4W",
        "outputId": "b449e9bf-354f-4431-87e0-6dea41aac626"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            " |-- bonus: long (nullable = true)\n",
            "\n",
            "+-------------+----------+-----+------+---+-----+\n",
            "|employee_name|department|state|salary|age|bonus|\n",
            "+-------------+----------+-----+------+---+-----+\n",
            "|James        |Sales     |NY   |90000 |34 |10000|\n",
            "|Michael      |Sales     |NV   |86000 |56 |20000|\n",
            "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
            "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
            "|Raman        |Finance   |DE   |99000 |40 |24000|\n",
            "|Scott        |Finance   |NY   |83000 |36 |19000|\n",
            "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
            "|Jeff         |Marketing |NV   |80000 |25 |18000|\n",
            "|Kumar        |Marketing |NJ   |91000 |50 |21000|\n",
            "+-------------+----------+-----+------+---+-----+\n",
            "\n",
            "+-----+----------+\n",
            "|state|sum_salary|\n",
            "+-----+----------+\n",
            "|   NV|    166000|\n",
            "|   CA|    171000|\n",
            "|   NY|    252000|\n",
            "|   NJ|     91000|\n",
            "|   DE|     99000|\n",
            "+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kS8L19IUdDIV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}